# Gesture-Controlled-Virtual-Mouse-and-Keyboard
 

A gesture-controlled virtual mouse makes it easier for people to connect with computers by utilizing hand gestures, voice commands, and eye movements. Computers seldom ever require direct contact. Static and dynamic hand gestures, voice assistance, and eye motions can be used to virtually control all input and output processes. Modern machine learning and computer vision techniques are used in the project to recognize hand gestures, voice commands, and eye movements using both internal and external cameras. The first module involves hand detection using MediaPipe's technology, while the second module involves a glove with a single color. Users can access keyboard keys by moving their fingers in the air, allowing them to work with a virtual keyboard. This is made possible through computer vision technology and artificial intelligence, using modules such as Hand Tracking, CVzone Hand Detector, and the Controller imported from the Pynput keyboard. The suggested system functions as a virtual keyboard and mouse without the need for any external devices, wires, or connections.  It uses a Convolutional Neural Network(CNN)-like model implemented by MediaPipe running on top of pybind11. It consists of two modules. The first works with your hand directly using MediaPipeâ€™s hand detection, while the second employs a glove with a single colour. By maneuvering fingers in air to access keyboard keys, users of the visual keyboard can work in the air. This is made possible by computer vision technology and artificial intelligence. To make the virtual keyboard function, we employ a variety of modules, including the Hand Tracking and CVzone Hand Detector Modules, as well as the Controller imported from the Pynput keyboard.The suggested system will function as a virtual keyboard and mouse without the necessity of a wire or any other external device. The webcam, which is the only piece of hardware in this system, is used to record images, recognise hand gestures, eye movements, and receive voice instructions using the Pyttsx3 module.

Note: Use Python version: 3.8.5



## Features

- VoiceBot 
  -  Current Date and Time                           
  -  Google Search
  -  Find Location
  -  File Navigation 
  -  Copy and Paste
  -  Sleep/Wake-up

- KeyBoard
- Eye Movements
- Gesture Recognition:
    - Neutral Gesture
    - Move Cursor
    - Left Click
    - Right Click
    - Double Click
    - Scrolling
    - Drag and Drop
    - Multiple Item Selection
    - Volume Control

